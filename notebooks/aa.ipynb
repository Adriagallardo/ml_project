{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "orig_nbformat": 4,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.7.4 64-bit"
  },
  "interpreter": {
   "hash": "54fd10a125f012059efbf68d746a102a68808834a5fa4f754a07e57618326eaa"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\u001b[1mDownloading and preparing dataset Unknown size (download: Unknown size, generated: Unknown size, total: Unknown size) to C:\\Users\\Adrià\\tensorflow_datasets\\iris\\2.0.0...\u001b[0m\n",
      "Dl Completed...: 0 url [00:00, ? url/s]\n",
      "Dl Completed...:   0%|          | 0/1 [00:00<?, ? url/s]\n",
      "Dl Completed...:   0%|          | 0/1 [00:01<?, ? url/s]\n",
      "Dl Completed...: 100%|██████████| 1/1 [00:01<00:00,  1.28s/ url]\n",
      "Dl Size...: 0 MiB [00:01, ? MiB/s]\n",
      "Dl Completed...: 100%|██████████| 1/1 [00:01<00:00,  1.29s/ url]\n",
      "Generating splits...:   0%|          | 0/1 [00:00<?, ? splits/s]\n",
      "Generating train examples...: 0 examples [00:00, ? examples/s]\u001b[A\n",
      "                                                              \u001b[A\n",
      "Shuffling iris-train.tfrecord...:   0%|          | 0/150 [00:00<?, ? examples/s]\u001b[A\n",
      "\u001b[1mDataset iris downloaded and prepared to C:\\Users\\Adrià\\tensorflow_datasets\\iris\\2.0.0. Subsequent calls will reuse this data.\u001b[0m\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "array([[ 9,  0,  0],\n",
       "       [ 0,  8,  0],\n",
       "       [ 0,  3, 10]], dtype=int64)"
      ]
     },
     "metadata": {},
     "execution_count": 1
    }
   ],
   "source": [
    "import tensorflow_datasets as tfds\n",
    "import tensorflow as tf\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "data, info = tfds.load('iris', split='train',\n",
    "                       as_supervised=True,\n",
    "                       shuffle_files=True,\n",
    "                       with_info=True)\n",
    "\n",
    "AUTOTUNE = tf.data.experimental.AUTOTUNE\n",
    "\n",
    "train_dataset = data.take(120).batch(4).prefetch(buffer_size=AUTOTUNE)\n",
    "test_dataset = data.skip(120).take(30).batch(4).prefetch(buffer_size=AUTOTUNE)\n",
    "\n",
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Dense(8, activation='relu'),\n",
    "    tf.keras.layers.Dense(16, activation='relu'),\n",
    "    tf.keras.layers.Dense(info.features['label'].num_classes, activation='softmax')\n",
    "    ])\n",
    "\n",
    "model.compile(loss='sparse_categorical_crossentropy', optimizer='adam', \n",
    "              metrics='accuracy')\n",
    "\n",
    "history = model.fit(train_dataset, validation_data=test_dataset, epochs=50, verbose=0)\n",
    "\n",
    "y_pred = model.predict(test_dataset)\n",
    "\n",
    "predicted_categories = tf.argmax(y_pred, axis=1)\n",
    "\n",
    "true_categories = tf.concat([y for x, y in test_dataset], axis=0)\n",
    "\n",
    "confusion_matrix(predicted_categories, true_categories)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "<PrefetchDataset shapes: ((None, 4), (None,)), types: (tf.float32, tf.int64)>"
      ]
     },
     "metadata": {},
     "execution_count": 2
    }
   ],
   "source": [
    "test_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}